{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Softmax\n",
    "from keras import Sequential\n",
    "from sklearn.preprocessing import scale\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = lambda imname: np.array(Image.open(imname).convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:47<00:00, 11.92s/it]\n"
     ]
    }
   ],
   "source": [
    "benign_processed = []\n",
    "path = '/Applications/GIAP/hp/BreaKHis_v1/histology_slides/breast/benign/SOB'\n",
    "for TYPE_NAME in tqdm.tqdm(os.listdir(path)):\n",
    "    FILE_PATH = os.path.join(path, TYPE_NAME)\n",
    "    for SUBFILE_NAME in os.listdir(FILE_PATH):\n",
    "        SUBFILE_PATH = os.path.join(FILE_PATH, SUBFILE_NAME)\n",
    "        for ZOOM_FILE in os.listdir(SUBFILE_PATH):\n",
    "            ZOOM_PATH = os.path.join(SUBFILE_PATH, ZOOM_FILE)\n",
    "            for IMAGE_NAME in os.listdir(ZOOM_PATH):\n",
    "                IMAGE_PATH = os.path.join(ZOOM_PATH, IMAGE_NAME)\n",
    "                _, ftype = os.path.splitext(IMAGE_PATH)\n",
    "                if ftype == '.png':\n",
    "                    img = read(IMAGE_PATH)\n",
    "                    img = cv2.resize(img, (256, 256))\n",
    "                    benign_processed.append(tf.convert_to_tensor(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:46<00:00, 26.59s/it]\n"
     ]
    }
   ],
   "source": [
    "malignant_processed = []\n",
    "path = '/Applications/GIAP/hp/BreaKHis_v1/histology_slides/breast/malignant/SOB'\n",
    "for TYPE_NAME in tqdm.tqdm(os.listdir(path)):\n",
    "    FILE_PATH = os.path.join(path, TYPE_NAME)\n",
    "    for SUBFILE_NAME in os.listdir(FILE_PATH):\n",
    "        SUBFILE_PATH = os.path.join(FILE_PATH, SUBFILE_NAME)\n",
    "        for ZOOM_FILE in os.listdir(SUBFILE_PATH):\n",
    "            ZOOM_PATH = os.path.join(SUBFILE_PATH, ZOOM_FILE)\n",
    "            for IMAGE_NAME in os.listdir(ZOOM_PATH):\n",
    "                IMAGE_PATH = os.path.join(ZOOM_PATH, IMAGE_NAME)\n",
    "                _, ftype = os.path.splitext(IMAGE_PATH)\n",
    "                if ftype == '.png':\n",
    "                    img = read(IMAGE_PATH)\n",
    "                    img = cv2.resize(img, (256, 256))\n",
    "                    malignant_processed.append(tf.convert_to_tensor(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_processed = benign_processed + malignant_processed\n",
    "total_processed = tf.random.shuffle(total_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 15:02:21.230023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (4, 4), strides=(2, 2), padding='same'),\n",
    "    Conv2D(64, (4, 4), strides=(2, 2), padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=(1, 1)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(32, activation=LeakyReLU(alpha=0.1)),\n",
    "    Dense(64, activation=LeakyReLU(alpha=0.1)),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='spare_categorical_crossentropy', optimizer='adam')\n",
    "model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
